{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7gDAP1ntB7q"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgDxH1aAtXqj"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel, BertModel, BertPreTrainedModel\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch import tensor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l1mpWQDtZcS"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"gap\", split='train')\n",
        "dataset_test = load_dataset(\"gap\", split='test')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class GAPDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "def encode_data(tokenizer, texts, max_length=512):\n",
        "    return tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
        "\n",
        "texts = dataset['Text']\n",
        "labels = [int(a) for a in dataset['A-coref']]\n",
        "encodings = encode_data(tokenizer, texts)\n",
        "gap_dataset = GAPDataset(encodings, labels)\n",
        "loader = DataLoader(gap_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "texts_test = dataset_test['Text']\n",
        "labels_test = [int(a) for a in dataset_test['A-coref']]\n",
        "encodings_test = encode_data(tokenizer, texts_test)\n",
        "gap_dataset_test = GAPDataset(encodings_test, labels_test)\n",
        "loader_test = DataLoader(gap_dataset_test, batch_size=8, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeytTOeatfOc"
      },
      "outputs": [],
      "source": [
        "class CorefResolver(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(config.hidden_dropout_prob),\n",
        "            nn.Linear(config.hidden_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.hidden_dropout_prob),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs[0]\n",
        "        combined = torch.mean(sequence_output, dim=1)\n",
        "        logits = self.classifier(combined).squeeze()\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.BCELoss()\n",
        "            logits = logits.view(-1)\n",
        "            loss = loss_fct(logits, labels.float())\n",
        "\n",
        "        return (loss, logits) if loss is not None else logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DjXVeSHtjDA"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CorefResolver.from_pretrained('bert-base-uncased').to(device)\n",
        "optimizer = Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "\n",
        "def train(model, data_loader, optimizer, epochs=5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            try:\n",
        "                loss, _ = model(input_ids, attention_mask, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                progress_bar.set_postfix(loss=f\"{total_loss / (progress_bar.last_print_n + 1):.4f}\")\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error during training: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        print(f\"Epoch {epoch+1}: Average Loss = {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "train(model, loader, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gySVqgaytoeQ"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    y_scores = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "\n",
        "            probabilities = torch.sigmoid(logits)\n",
        "            custom_threshold = 0.7\n",
        "            predictions = (probabilities > custom_threshold).float()\n",
        "            y_pred.extend(predictions.cpu().numpy())\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_scores.extend(probabilities.cpu().numpy())\n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1,\n",
        "        \"Confusion Matrix\": cm,\n",
        "        \"AUC\": auc\n",
        "    }\n",
        "\n",
        "results = evaluate_model(model, loader_test)\n",
        "print(\"Evaluation Results:\", results)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_fgmheCKs42P"
      ],
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
